{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe Test.ipynb                \u001b[1m\u001b[34mpoemfiles\u001b[m\u001b[m/\r\n",
      "Image VAE.ipynb                 poetry_foundation_scraper.py\r\n",
      "Study Data.ipynb                poetry_scraper_improved.py\r\n",
      "\u001b[1m\u001b[31mchromedriver\u001b[m\u001b[m*                   poetry_scraper_improved_old.py\r\n",
      "edited_poems.csv                \u001b[1m\u001b[34mresults\u001b[m\u001b[m/\r\n",
      "full_scraper.py                 rhyme_dict_full.txt\r\n",
      "\u001b[1m\u001b[34mglove\u001b[m\u001b[m/                          rhyme_dict_simple.txt\r\n",
      "\u001b[1m\u001b[31mlyrics_billboard.csv\u001b[m\u001b[m*           rhyme_phones.txt\r\n",
      "\u001b[1m\u001b[31mlyrics_large.csv\u001b[m\u001b[m*               \u001b[1m\u001b[34mscraper\u001b[m\u001b[m/\r\n",
      "\u001b[1m\u001b[31mlyrics_small.csv\u001b[m\u001b[m*               scraper.py\r\n",
      "\u001b[1m\u001b[34mmlcourse\u001b[m\u001b[m/                       small_poem_set.csv\r\n",
      "poem_VAE.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.examples import sentences\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "def print_stuff(s, simple=False): \n",
    "    doc = nlp(s)\n",
    "    print(doc.text)\n",
    "    for token in doc:\n",
    "        if simple:\n",
    "            print(token.text, token.pos_, end=' ')\n",
    "        else:\n",
    "            print(token.text, token.pos_, token.dep_)\n",
    "    print(\"\\n----------------------\\n\")\n",
    "\n",
    "poems = pd.read_csv(\"small_poem_set.csv\")\n",
    "poems = poems.iloc[:, 1]\n",
    "#for i in range(2):\n",
    "#    print_stuff(poems[i], simple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from spacy.vocab import Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvocab = Vocab()\\ncount = 0\\nerrors = 0\\nwith open(glove_filename) as file:\\n    for line in file:\\n        count += 1\\n        word = line.split()[0]\\n        try:\\n            vector = np.array([float(d) for d in line.split()[1:]])\\n            vocab.set_vector(word, vector)\\n        except:\\n            errors += 1\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_filename = './glove/glove.840B.300d.txt'\n",
    "\n",
    "with open(glove_filename) as file:\n",
    "    words = [line.split()[0] for line in file]\n",
    "    \n",
    "\"\"\"\n",
    "vocab = Vocab()\n",
    "count = 0\n",
    "errors = 0\n",
    "with open(glove_filename) as file:\n",
    "    for line in file:\n",
    "        count += 1\n",
    "        word = line.split()[0]\n",
    "        try:\n",
    "            vector = np.array([float(d) for d in line.split()[1:]])\n",
    "            vocab.set_vector(word, vector)\n",
    "        except:\n",
    "            errors += 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_set = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many poems have vector representations\n",
    "def print_stuff(s, simple=False): \n",
    "    doc = nlp(s)\n",
    "    print(doc.text)\n",
    "    for token in doc:\n",
    "        if simple:\n",
    "            print(token.text, token.pos_, end=' ')\n",
    "        else:\n",
    "            print(token.text, token.pos_, token.dep_)\n",
    "    print(\"\\n----------------------\\n\")\n",
    "\n",
    "poems = pd.read_csv(\"small_poem_set.csv\")\n",
    "poems = poems.iloc[:, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
